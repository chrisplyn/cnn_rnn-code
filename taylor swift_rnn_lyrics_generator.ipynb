{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 25\n",
    "\n",
    "path = \"output.txt\"\n",
    "string_utf8 = open(path, \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processData(string, seq_maxlen=25, char_idx=None):\n",
    "\n",
    "    if char_idx is None:\n",
    "        char_idx = chars_to_dictionary(string)\n",
    "\n",
    "    len_chars = len(char_idx)\n",
    "\n",
    "    sequences = []\n",
    "    next_chars = []\n",
    "\n",
    "    for i in range(0, len(string) - seq_maxlen - 1):\n",
    "        sequences.append(string[i:i+seq_maxlen])\n",
    "        next_chars.append(string[i+1:i+seq_maxlen+1])\n",
    "\n",
    "    X = np.zeros((len(sequences), seq_maxlen, len_chars), dtype=np.bool)\n",
    "    Y = np.zeros((len(sequences), seq_maxlen, len_chars), dtype=np.bool)\n",
    "\n",
    "    for i, seq in enumerate(sequences):\n",
    "        for t, char in enumerate(seq):\n",
    "            X[i, t, char_idx[char]] = 1\n",
    "            Y[i, t, char_idx[next_chars[i][t]]] = 1\n",
    "\n",
    "    return X, Y, char_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(a, temperature):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.log(a) / temperature\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(model, seq_length, maxlen, temperature, char_idx_dic, idx_char_dic, seq_seed=None):\n",
    "\n",
    "    generated = seq_seed[:]\n",
    "    sequence = seq_seed[:]\n",
    "    whole_sequence = seq_seed[:]\n",
    "\n",
    "    for i in range(seq_length):\n",
    "        x = np.zeros((1, maxlen, len(char_idx_dic)))\n",
    "        for t, char in enumerate(sequence):\n",
    "            x[0, t, char_idx_dic[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x)[0][-1]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = idx_char_dic[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sequence = sequence[1:] + next_char\n",
    "        whole_sequence += next_char\n",
    "        \n",
    "    return whole_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 25\n",
    "X, Y, char_idx = \\\n",
    "    processData(string_utf8, seq_maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129945, 25, 82)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "yp = tf.placeholder(shape=[None, maxlen, len(char_idx)], dtype=tf.float32)                       \n",
    "\n",
    "g = tflearn.input_data([None, maxlen, len(char_idx)])\n",
    "g = tflearn.lstm(g, 512, return_seq=True)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.lstm(g, 512, return_seq=True)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.time_distributed(g, tflearn.fully_connected, [len(char_idx)])               \n",
    "g = tflearn.softmax(g)                                                      \n",
    "g = tflearn.reshape(g, [-1, maxlen, len(char_idx)])   \n",
    "\n",
    "g = tflearn.regression(g, optimizer='adam', loss='categorical_crossentropy',\n",
    "                       learning_rate=0.001,placeholder=yp)\n",
    "\n",
    "\n",
    "model = tflearn.DNN(g, tensorboard_verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 36559  | total loss: \u001b[1m\u001b[32m0.56599\u001b[0m\u001b[0m | time: 100.720s\n",
      "| Adam | epoch: 020 | loss: 0.56599 - acc: 0.3928 -- iter: 116928/116950\n",
      "Training Step: 36560  | total loss: \u001b[1m\u001b[32m0.54941\u001b[0m\u001b[0m | time: 104.709s\n",
      "| Adam | epoch: 020 | loss: 0.54941 - acc: 0.3910 | val_loss: 0.46943 - val_acc: 0.4010 -- iter: 116950/116950\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=10,validation_set=0.1, show_metric=True,\n",
    "          batch_size=64,run_id='talyor_swift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_char_dic = {v: k for k, v in char_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' you tell me what more do'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Randomly generate a short piece of lyrics as starting point\n",
    "'''\n",
    "seed = random_sequence_from_string(string_utf8, maxlen)\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "output_seq = generate(model, 2000, maxlen, 0.85, char_idx, idx_char_dic, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' you tell me what more do I need\\nAnd they\\'ll be chasing me this long\\nBaby but I figure it out\\nDon\\'t know what\\'s down this road, I\\'m just walked by\\nBut you had to talk about the good times, you and I\\n\\'Cause, baby, now we got bad blood\\nHey\\nAll is quiet in the world to let it go free\\nAnd this love came back down\\nTalk dark and be us the should step in\\nAnd force us in a simple way\\nIf I don\\'t know if I should.\\nI knew his world moved too fast and burned too free\\nAnd this love came back to me\\nThis love left a permanent mark\\nThis love is glowing in the dark\\nThese hands had to let it go free\\nAnd this love is glowing in the dark\\nThese hands had to let it go free\\nAnd this love came back down\\nLa, la, la\\nWhen you come back down\\nLa, la, la\\nWhen you come back down\\nLa, la, la\\nWhen you come back down\\nLa, la, la\\nWhen you come back down\\nLa, la,\\nHe can\\'t keep his wild eyes on the drought was the very worst\\nWhen the flowers through his hair\\nI\\'m laughing Last forever and ever\\nThere you stand tear\\nI watched superman fly away\\nCome back ill be with you someday\\nI like the other says \"he will\\nHe says \"God,I didn\\'t even say anything\\nI didn\\'t showe\\nYeah I\\'m just gonna shake,shake,shake,shake\\nYeah Ohhh\\n[chorus]\\nCause we\\'re young and we\\'re reckless\\nWe thought were stars\\nMemry was\\nNothing in the world can ever once destroy\\nthe dream of an age\\nOh yeah\\nBut that\\'s ok\\n[Chorus]\\nMame in the same words\\ncoustance to this is getting good usnow pane, looking red\\nLoving him is like driving a reason to go\\nOh no\\nShe didn\\'t have a reason to go\\nOh no\\nShe didn\\'t take the players\\nAnd yeah\\nI could tell you now\\nBut baby never met\\nCause lovis she thinks about it when she sees headle of you and me in the palm of your hand\\nThen, why\\'d you had to go and lock me out when I let you in\\nStaye I just like the two of us\\nSo this is me swallowing my pride,\\nStanding in front of you saying \"It\\'s gonna be alright.\"\\n[chorus]\\nCause I\\'m a saw you there and I\\'m cursing your name until you come back home\\n[Bridge: Talling for it screaming that you like\\nAnd when '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "file = codecs.open(\"talyor swift.txt\", \"w\", \"utf-8\")\n",
    "file.write(output_seq)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
